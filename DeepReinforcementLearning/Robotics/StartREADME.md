# Ishmael Rogers
# Robotics Software Engineer 
# Infinitely Deep Robotics Group
# Introduction to Reinforcement Learning for Robotics
# www.idrg.io
# 2019


Deep Reinforcement Learning for Robotics is a paradigm shift. The basic idea is to start with raw sensor input, define a goal for the robot, and let it figure out through trial and error, the best way to achieve the goal. In this paradigm, perception, interal state, planning, control and even sensor measurement uncertainty are no explicity defined. The traidtional steps between observation (sensory input) and actionable output are learned by a neural network. 

[image1]

In 2015, Google's DeepMind AlphaGo made history in the AI world by using Deep Reinforcment Learning to beat a human professional in the complex game of *Go* During the game, AlphaGo used original moves that it had come up with on its own. These moves taught us new knowledge about this ancient game. 

AlphaGo optimized its own moves based on the goal of winning rather than looking at possible moves and choosing a likely response based on a library of examples. 

In robotics, Deep RL can also be used to find the optimal solution to a problem. Traditionally, an idustrial robot needs to be precisely programmed in a tightly controll environment in order to do something like grasp an object. This can be computationally expensive and time-consuming. 

Deep RL allows robots to train themselves to perform a new task. For the Fenix robot, it tries picking up object while capturing video footage in the process. Each time it suceeds or fails it refines the [Deep Neural Network](link1) that controls its action.

Warehousing companies that already use robots are looking at Deep RL to lower costs. Companies like Amazon, with fulfillment centers that deploy thousands of robots are highly motivated to use innovative technologies like Deep RL to opimizae their resources and remain competitive in the marketplace.

Companies such as Google, Autodesk, and Amazon are actively working on Deep RL solutions in robotics. 
